---
title: "Machine Learning Project"
author: "S Grimsley"
date: "November 1, 2016"
output: 
  html_document: 
    keep_md: yes
---

The purpose of this project is to develop a model to accurately predict how participants performed a Dumbbell Biceps Curl, using the Weightlifting Exercises Dataset.  Exercises were separated into 5 classes; class A is the correct form, and B - D are different incorrect forms as defined by the experimenters.

Exploratory analysis led to the reduction of the data to 54 variables (from 160).  The training data was split into a training (75%) and test set, and a random forest model developed using k-fold cross validation (k=10).  The model performed well when applied to the test set, with an accuracy of 99.35% and Kappa of 99.17%.  The model accurately predicted all 20 test cases from the test dataset.

Data Citation:
Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013. 

URL: http://groupware.les.inf.puc-rio.br/har


###Data Processing / Exploratory Analysis

Training and test data were downloaded from:

* Training: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv
* Test: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

```{r error=FALSE, message=FALSE}
library(caret)
train <- read.csv("pml-training.csv", stringsAsFactors=FALSE)
names <- colnames(train)
```

Dimensions in training set:
```{r}
dim(train)
```

Exploratory analysis of the data showed 100 variables had values that were primarily N/A or empty strings (97.9% within these variable).  Review of the experimenter's methodology show these were computed values, based on time slices of 2.5 seconds, with results stored in the record at the beginning of each time window.  These variables were removed, instead of imputing the data, because a similar imputation would not be possible on the final test data.  

I considered whether a time-series model was appropriate, but ruled that out because the test data was not structured in that manner (isolated records were provided, instead of entire time windows).

The data was ordered sequentially, both by number (variable X) and time window measures (timestamps, windows).  I removed these variables after column X proved to be the most important variable (varImp of 100%) in an earlier version of the model.

```{r error=FALSE, message=FALSE}
# Testing for and removing high proportion of NAs
isna <- lapply(train[,],function(x)sum(is.na(x))/length(train$classe))
remove<- isna[names(which(isna >0))]
train2 <- train[-which(colnames(train) %in% names(remove))]

# Test for and removing high proportion of empty character strings
isna2<-lapply(train2[,],function(x)sum(x=="")/length(train2$classe))
remove2<- isna2[names(which(isna2 >0))]
train2 <- train2[-which(colnames(train2) %in% names(remove2))]

# Remove ordered variables (row numbers and time window measures)
remove3 <- c(1,3:7)
train2 <- train2[,-remove3]
```

After processing, the training dataset contained 54 variables, instead of 160.  
```{r}
dim(train2)
```

As an alternative, I considered removing variables with near zero variance.  Near zero variance would have only removed 60 variables, so I decided to use the method described above.

```{r}
nsv <- nearZeroVar(train, saveMetrics=TRUE)
length(nsv$nzv[which(nsv$nzv==TRUE)])
```

The training data was split into training (75%) and test sets.

```{r error=FALSE, message=FALSE}
# Separate into training and test sets
set.seed(6483147)
inTrain <- createDataPartition(y=train2$classe, p=0.75, list=FALSE)
training <- train2[inTrain,]
testing <- train2[-inTrain,]
```

###Model Development

The caret package was used to fit a random forest model on the training set, using k-fold cross validation (k = 10) and parallel processing.

```{r cache=TRUE, error=FALSE, message=FALSE}
library(parallel)
library(doParallel)
cluster <- makeCluster(detectCores() -1)
registerDoParallel(cluster)

# set trainControl to use k-fold cross validation (k=10) and allow parallel processing
fitControl <- trainControl(method = "cv", number = 10, allowParallel=TRUE)

# fit random forest model
modFit <- train(classe ~., data=training, method="rf", trControl=fitControl)

stopCluster(cluster)
```

The model performed with a 99.36% accuracy, and Kappa of 99.19%.

```{r}
modFit
plot(modFit)
```

The model was applied to the testing data, resulting in an accuracy of 99.35% and Kappa of 99.17%.  These measures are more accurate for how the model will perform on an independant data set.

```{r error=FALSE, message=FALSE}
pred <- predict(modFit, newdata=testing)
confusionMatrix(pred, testing$classe)
```

Due to the high accuracy and Kappa, this model will be applied to the testing set.

###Results
The test data was input and processed in the same manner as the training data (removing variables), and predictions generated from the model.  

```{r}
test <- read.csv("pml-testing.csv", stringsAsFactors=FALSE)

# Remove same columns as the testing data
test2 <- test[-which(colnames(test) %in% names(remove))]
test2 <- test2[-which(colnames(test2) %in% names(remove2))]  
test2 <- test2[,-remove3]

# Predictions for quiz
predquiz <- predict(modFit, newdata=test2)
```

The predictions were 100% accurate for the test set, based on the results of the project quiz.  This shows the model is accurate at predicting how participants performed a Dumbbell Biceps curl.  Since user_name was not a variable of importance (see below), the model should be able to predict the classe for people not included in the initial study.  (It would be interesting to test this.) 

```{r}
varImp(modFit)
```

